{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Training - Parton Level\n",
    "This notebook can be ran if one wishes to train again the Neural Networks used for the analysis at the parton level. This is not recommended due to the computational costs involved. Each notebook calls and trains a NN for each Wilson coefficient. The new model weights can be saved by setting the parameter `save` to `True` in the `train_test_model` function, and by specifying a destination folder to store the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "import utils.partonicXS \n",
    "import utils.protonXS \n",
    "import utils.tt_prod_ML4EFT\n",
    "import utils.validation\n",
    "from utils.funcs import parton_data_preprocessing, dataset_loader, MLP, train_test_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette('Set2')\n",
    "sns.set_palette(palette)\n",
    "plt.rcParams['text.usetex'] = False\n",
    "p = {'size': 18, 'family': 'cmr10'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and preprocess data\n",
    "path_to_MC = '../data/PartonLevel/MonteCarlo_PL'\n",
    "X, Xsm, Xc8dt, y = parton_data_preprocessing('c8dt', path_to_MC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#specify parameters \n",
    "test_size = 0.2\n",
    "random_state = 42\n",
    "batch_size = 150000\n",
    "\n",
    "#define train and test set\n",
    "train_loader, test_loader = dataset_loader(X, y, test_size, random_state, batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: MLP(\n",
      "  (layer1): Linear(in_features=2, out_features=50, bias=True)\n",
      "  (layer2): Linear(in_features=50, out_features=70, bias=True)\n",
      "  (layer3): Linear(in_features=70, out_features=150, bias=True)\n",
      "  (layer4): Linear(in_features=150, out_features=100, bias=True)\n",
      "  (layer5): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (layer6): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#call the model\n",
    "model = MLP().to(device)\n",
    "\n",
    "print(f\"Model structure: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary cross entropy loss\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "#hyperparameters\n",
    "learning_rate = 0.0003\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, test_loss = train_test_model(model, criterion, optimizer, train_loader, test_loader, epochs=200, save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = min(train_loss)\n",
    "min_loss_index = train_loss.index(min_loss)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_loss, linewidth=2, label = 'Train loss')\n",
    "plt.plot(test_loss, linewidth=2 , label = 'Test loss')\n",
    "plt.scatter(min_loss_index, min_loss, color='red', label=f'Minimum = {min_loss:.3f}')\n",
    "plt.xlabel('Epoch', fontdict=p)\n",
    "plt.ylabel('BCE Loss', fontdict=p)\n",
    "plt.legend(prop = p, loc='upper right')\n",
    "plt.title('Loss per epoch (SM vs $c^{(8)}_{dt}$ data)', fontdict=p)\n",
    "plt.xticks(**p)\n",
    "plt.yticks(**p)\n",
    "#plt.savefig('../plots/Loss_c8dt_PartonLevel.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "findNP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
